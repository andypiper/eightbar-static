<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Nick O&#8217;Leary &#8211; eightbar</title>
	<atom:link href="http://eightbar.co.uk/author/nol/feed/" rel="self" type="application/rss+xml" />
	<link>http://eightbar.co.uk</link>
	<description>Raising The Eight Bar</description>
	<lastBuildDate>Tue, 26 Jul 2016 09:38:58 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.5.3</generator>
	<item>
		<title>A Conversational Internet of Things – ThingMonk talk</title>
		<link>http://eightbar.co.uk/2014/12/04/a-conversational-internet-of-things-thingmonk-talk/</link>
		<pubDate>Thu, 04 Dec 2014 22:00:55 +0000</pubDate>
		<dc:creator><![CDATA[Nick O'Leary]]></dc:creator>
				<category><![CDATA[Events]]></category>
		<category><![CDATA[Planet]]></category>
		<category><![CDATA[eightbar]]></category>

		<guid isPermaLink="false">http://knolleary.net/?p=1663</guid>
		<description><![CDATA[Earlier this year, Tom Coates wrote a blog post about his session at this year&#8217;s O&#8217;Reilly Foo Camp. Over tea with colleagues, we talked about some of the ideas from the post and how some of our research work might be interesting when applied to them. One thing led to another and I found myself [&#8230;] <a href="http://eightbar.co.uk/2014/12/04/a-conversational-internet-of-things-thingmonk-talk/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p><i>Earlier this year, Tom Coates wrote a <a href="https://medium.com/product-club/interacting-with-a-world-of-connected-objects-875b4a099099">blog post</a> about his session at this year&#8217;s O&#8217;Reilly Foo Camp. Over tea with colleagues, we talked about some of the ideas from the post and how some of our research work might be interesting when applied to them.</i></p>
<p>One thing led to another and I found myself talking about it at ThingMonk this year. What follows is a slightly expanded version of my talk.<br />
</p>
<hr />
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-0-300x168.png" alt="ciot-0" width="300" height="168" class="aligncenter size-medium wp-image-1666" style="box-shadow: 1px 1px 8px #999;" /></p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-2-300x168.png" alt="ciot-2" width="300" height="168" class="aligncenter size-medium wp-image-1667" style="box-shadow: 1px 1px 8px #999;" /></p>
<p><b>Humanising Things</b></p>
<p>We have a traditional of putting human faces on things. Whether it&#8217;s literally seeing faces on the Things in our everyday lives, such as the <a href="https://www.flickr.com/photos/dbtelford/6967361278/">drunk octopus</a> spoiling for a fight, or possibly the most <a href="https://www.flickr.com/photos/blackbeltjones/5089926442/">scary drain pipe</a> ever.</p>
<p>Equally, we have a tendency to put a human persona onto things. The advent of Twitter brought an onslaught of Things coming online. It seemingly isn&#8217;t possible for me to do a talk without at least a fleeting mention of Andy Standford-Clark&#8217;s twittering ferries; where regular updates are provided for where each ferry is.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-5-300x168.png" alt="ciot-5" width="300" height="168" class="aligncenter size-medium wp-image-1668" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>One of the earliest Things on Twitter was Tower Bridge. Tom Armitage, who was working near to the bridge at the time, wrote some code that grabbed the schedule for the bridge opening and closing times, and created the account to relay that information.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-6-300x168.png" alt="ciot-6" width="300" height="168" class="aligncenter size-medium wp-image-1669" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>One key difference between the ferries and the bridge is that the ferries are just relaying information, a timestamp and a position, whereas the bridge is speaking to us in the first-person. This small difference immediately begins to bring a more human side to the account.<br />
But ultimately, they are simple accounts that relay their state with whomever is following them.</p>
<p>This sort of thing seems to have caught on particularly with the various space agencies. We no longer appear able to send a robot to Mars, or land a probe on a comet without an accompanying twitter account bringing character to the events.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-7-300x168.png" alt="ciot-7" width="300" height="168" class="aligncenter size-medium wp-image-1683" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>There&#8217;s always a sense of excitement when these inanimate objects start to have a conversation with one another. The conversations between the philae lander and its orbiter were particularly touching as they waved goodbye to one another. Imagine, the lander, which was launched into space years before Twitter existed, chose to use its last few milliamps of power to send a final goodbye.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-8-300x168.png" alt="ciot-8" width="300" height="168" class="aligncenter size-medium wp-image-1684" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>But of course as soon as you peek behind the curtain, you see someone running Tweetdeck, logged in and typing away. I was watching the live stream as the ESA team were nervously awaiting to hear from philae. And I noticed the guy in the foreground, not focused on the instrumentation as his colleagues were, but rather concentrating on his phone. Was he the main behind the curtain, preparing Philae&#8217;s first tweet from the surface? Probably not, but for the purposes of this talk, let&#8217;s pretend he was.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-9-300x168.png" alt="ciot-9" width="300" height="168" class="aligncenter size-medium wp-image-1670" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>The idea of giving Things a human personality isn&#8217;t a new idea. There is a wealth of rigorous scientific research in this area.</p>
<p>One esteemed academic, Douglas Adams, tells us about the work done by the The Sirius Cybernetics Corporation, who invented a concept called Genuine People Personalities (&#8220;GPP&#8221;) which imbue their products with intelligence and emotion.</p>
<p>He writes:</p>
<blockquote><p>Thus not only do doors open and close, but they thank their users for using them, or sigh with the satisfaction of a job well done. Other examples of Sirius Cybernetics Corporation&#8217;s record with sentient technology include an armada of neurotic elevators, hyperactive ships&#8217; computers and perhaps most famously of all, Marvin the Paranoid Android. Marvin is a prototype for the GPP feature, and his depression and &#8220;terrible pain in all the diodes down his left side&#8221; are due to unresolved flaws in his programming.
</p></blockquote>
<p>In a related field, we have the <a href="http://knolleary.net/2014/12/04/a-conversational-internet-of-things-thingmonk-talk/reddwarf.wikia.com/wiki/Talkie_Toaster">Talkie Toaster</a> created by Crapola, Inc and seen aboard Red Dwarf. The novelty kitchen appliance was, on top of being defective, only designed to provide light conversation at breakfast time, and as such it was totally single-minded and tried to steer every conversation to the subject of toast.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-13-300x168.png" alt="ciot-13" width="300" height="168" class="aligncenter size-medium wp-image-1671" style="box-shadow: 1px 1px 8px #999;" /></p>
<p><b>Seam[less|ful]ness</b></p>
<p>In this era of the Internet of Things, we talk about a future where our homes and workplaces are full of connected devices, sharing their data, making decisions, collaborating to make our lives &#8216;better&#8217;.</p>
<p>Whilst there are people who celebrate this invisible ubiquity and utility of computing, the reality is going to much more messy.</p>
<p><a href="http://en.wikipedia.org/wiki/Mark_Weiser">Mark Weiser</a>, Chief Scientist at Xerox PARC, coined the term &#8220;ubiquitous computing&#8221; in 1988.</p>
<blockquote><p>Ubiquitous computing names the third wave in computing, just now beginning. First were mainframes, each shared by lots of people. Now we are in the personal computing era, person and machine staring uneasily at each other across the desktop. Next comes ubiquitous computing, or the age of calm technology, when technology recedes into the background of our lives.</p></blockquote>
<p>Discussion of Ubiquitous Computing often celebrated the idea of seamless experiences between the various devices occupying our lives. But in reality, Mark Weiser advocated for the opposite; that seamlessness was undesirable and self-defeating attribute of such a system.</p>
<p>He preferred a vision of &#8220;Seamfulness, with beautiful seams&#8221;</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-15-300x168.png" alt="ciot-15" width="300" height="168" class="aligncenter size-medium wp-image-1673" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>The desire to present a single view of the system, with no joins, is an unrealistic aspiration in the face of the cold realities of wifi connectivity, battery life, system reliability and whether the Cloud is currently turned on.</p>
<p>Presenting a user with a completely monolithic system gives them no opportunity to connect with and begin to understand the constituent parts. That is not it say this information is needed to all users all of the time. But there is clearly utility to some users some of the time.</p>
<p>When you come home from work and the house is cold, what went wrong? Did the thermostat in the living room break and decide it was the right temperature already? Did the message from the working thermostat fail to get to the boiler? Is the boiler broken? Did you forgot to cancel the entry in your calendar saying you&#8217;d be late home that day?</p>
<p>Without some appreciation of the moving parts in a system, how can a user feel any ownership or empowerment when something goes wrong with it. Or worse yet, how can they avoid feeling anything other than intimidated by this monolithic system that simply says &#8220;I&#8217;m Sorry Dave, I&#8217;m afraid I can&#8217;t do that&#8221;.</p>
<p>Tom Armitage <a href="http://tomarmitage.com/2014/12/02/some-of-these-things-are-not-like-the-others/">wrote up his</a> talk from Web Directions South and published it earlier this week, just as I was writing this talk. He covers a lot of what I&#8217;m talking about here so much more eloquently than I am &#8211; go read it. One piece his post pointed me at that I hadn&#8217;t seen was <a href="http://knolleary.net/2014/12/04/a-conversational-internet-of-things-thingmonk-talk/techcrunch.com/2014/10/14/august-smart-lock-on-sale/">Techcrunch&#8217;s recent review of August&#8217;s Smart Lock</a>.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-16-300x168.png" alt="ciot-16" width="300" height="168" class="aligncenter size-medium wp-image-1674" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>Tom picked out some choice quotes from the review which I&#8217;ll share here:</p>
<blockquote><p>“…much of the utility of the lock was negated by the fact that I have roommates and not all of them were willing or able to download the app to test it out with me […] My dream of using Auto-Unlock was stymied basically because my roommates are luddites.”
</p></blockquote>
<blockquote><p>“Every now and then it didn’t recognize my phone as I approached the door.”</p></blockquote>
<blockquote><p>“There was also one late night when a stranger opened the door and walked into the house when August should have auto-locked the door.”</p></blockquote>
<p>This is the reason for having beautiful seams; seams help you understand the edges of a devices sphere of interaction, but should not be so big to trip you up. Many similar issues exists with IP connected light bulbs. When I need to remember which app to launch on my phone depending on which room I&#8217;m walking into, and which bulbs happen to be in there, the seams have gotten too big.</p>
<p>In a recent <a href="<a href="https://medium.com/product-club/interacting-with-a-world-of-connected-objects-875b4a099099">blog post</a>, Tom Coates wrote about the idea of a chatroom for the house &#8211; go read it.</p>
<blockquote><p>Much like a conference might have a chatroom, so might a home. And it might be a space that you could duck into as you pleased to see what was going on. By turning the responses into human language you could make the actions of the objects less inscrutable and difficult to understand.</p></blockquote>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-17-300x168.png" alt="ciot-17" width="300" height="168" class="aligncenter size-medium wp-image-1675" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>This echoes back to the world of Twitter accounts for Things. But rather than them being one-sided conversations presenting raw data in a more consumable form, or Wizard-of-Oz style man-behind-the-curtain accounts, a chatroom is a space where the conversation can flow both ways; both between the owner and their devices, but also between the devices themselves.</p>
<p>What might it take to turn such a chatroom into a reality?</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-18-300x168.png" alt="ciot-18" width="300" height="168" class="aligncenter size-medium wp-image-1676" style="box-shadow: 1px 1px 8px #999;" /></p>
<p><b>Getting Things Talking</b></p>
<p>Getting Things connected is no easy task.</p>
<p>We&#8217;re still in the early days of the protocol wars.</p>
<p>Whilst I have to declare allegiance to the now international OASIS standard MQTT, I&#8217;m certainly not someone who thinks one protocol will rule them all. It pains me whenever I see people make those sorts of claims. But that&#8217;s a talk for a different day.</p>
<p>Whatever your protocol of choice, there are an emerging core set that seem to be the more commonly talked about. Each with its strengths and weaknesses. Each with its backers and detractors.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-19-300x168.png" alt="ciot-19" width="300" height="168" class="aligncenter size-medium wp-image-1677" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>What (mostly) everyone agrees on is the need for more than just efficient protocols for the Things to communicate by. A protocol is like a telephone line. It&#8217;s great that you and I have agreed on the same standards so when I dial this number, you answer. But what do we say to each other once we&#8217;re connected? A common protocol does not mean I understand what you&#8217;re trying to say to me.</p>
<p>And thus began the IoT meta-model war.</p>
<p>There certainly a lot of interesting work being done in this area.</p>
<p>For example, HyperCat, a consortium of companies coming out of a Technology Strategy Board funded Demonstrator project in the last year or so.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-21-300x168.png" alt="ciot-21" width="300" height="168" class="aligncenter size-medium wp-image-1678" style="box-shadow: 1px 1px 8px #999;" /></p>
<blockquote><p>HyperCat is an open, lightweight JSON-based hypermedia catalogue format for exposing collections of URIs. Each HyperCat catalogue may expose any number of URIs, each with any number of RDF-like triple statements about it. HyperCat is simple to work with and allows developers to publish linked-data descriptions of resources.
</p></blockquote>
<p>URIs are great. The web is made of them and they are well understood. At least, they are well understood by machines. What we&#8217;re lacking is the human view of this world. How can this well-formed, neatly indented JSON be meaningful or helpful to the user who is trying to understand what is happening.</p>
<p>This is by no means a criticism of HyperCat, or any of the other efforts to create models of the IoT. They are simply trying to solve a different set of problems to the ones I&#8217;m talking about today.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-23-300x168.png" alt="ciot-23" width="300" height="168" class="aligncenter size-medium wp-image-1679" style="box-shadow: 1px 1px 8px #999;" /></p>
<p><b>Talking to Computers</b></p>
<p>We live in an age where the talking to computers is becoming less the reserve of science fiction.</p>
<p>Siri, OK Google, Cortana all exist as ways to interact with the devices in your pocket. My four year old son walks up to me when I have my phone out and says: &#8220;OK Google, show me a picture of the Octonauts&#8221; and takes over my phone without even having to touch it. To him, as to me, voice control is still a novelty. But I wonder what his 6 month old sister will find to be the intuitive way of interacting with devices in a few years time.</p>
<p>The challenge of Natural Language Parsing, NLP, is one of the big challenges in Computer Science. Correctly identifying the words being spoken is relatively well solved. But understanding what those words mean, what intent they try to convey, is still a hard thing to do.</p>
<p>To answer the question &#8220;Which bat is your favourite?&#8221; without any context is hard to do. Are we talking to a sportsman with their proud collection of cricket bats? Is it the zoo keeper with their colony of winged animals. Or perhaps a comic book fan being asked to chose between George Clooney and Val Kilmer.</p>
<p>Context is also key when you want to hold a conversation. The English language is riddled with ambiguity. Our brains are constantly filling in gaps, making theories and assertions over what the other person is saying. The spoken word also presents its own challenges over the written word.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-28-300x168.png" alt="ciot-28" width="300" height="168" class="aligncenter size-medium wp-image-1680" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>&#8220;Hu was the premiere of China until 2012&#8243;</p>
<p>When said aloud, you don&#8217;t know if I&#8217;ve asked you a question or stated a fact. When written down, it is much clearer.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-29-300x168.png" alt="ciot-29" width="300" height="168" class="aligncenter size-medium wp-image-1681" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>In their emerging technology report for 2014, Gartner put the Internet of Things at the peak of inflated expectation. But if you look closely at the curve, up at the peak, right next to IoT, is NLP Question Answering. If this was a different talk, I&#8217;d tell you all about how IBM Watson is solving those challenges. But this isn&#8217;t that talk.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-30-300x168.png" alt="ciot-30" width="300" height="168" class="aligncenter size-medium wp-image-1682" style="box-shadow: 1px 1px 8px #999;" /></p>
<p><b>A Conversational Internet of Things</b></p>
<p>To side step a lot of the challenges of NLP, one area of research we&#8217;re involved with is that of Controlled Natural Language and in particular, Controlled English.</p>
<p>CE is designed to be readable by a native English speaker whilst representing information in a structured and unambiguous form. It is structured by following a simple but fully defined syntax, which may be parsed by a computer system.</p>
<p>It is unambiguous by using only words that are defined as part of a conceptual model.</p>
<p>CE serves as a language that is both understandable by human and computer system &#8211; which allows them to communicate.</p>
<p>For example,</p>
<pre>there is a thermometer named t1 that is located in the room r1</pre>
<p>A simple sentence that establishes the fact that a thermometer exists in a given room.</p>
<pre>the thermometer t1 can measure the environment variable temperature</pre>
<p>Each agent in the system builds its own model of the world that can be used to define concepts such thermometer, temperature, room and so on. As the model is itself defined in CE, the agents build their models through conversing in CE.</p>
<pre>there is a radiator valve v1 that is located in the room r1
the radiator valve v1 can control the environment variable temperature</pre>
<p>It is also able to using reasoning to determine new facts. </p>
<pre>the room r1 has the environment variable temperature that can be measured and that can be controlled</pre>
<p>As part of some research work with Cardiff University, we&#8217;ve been looking at how CE can be extended to a conversational style of interaction.</p>
<p>These range from exchanging facts between devices &#8211; the tell</p>
<pre>the environment variable temperature in room r1 has value "21"</pre>
<p>Being able to ask question &#8211; ask-tell</p>
<pre>for which D1 is it true that
      ( the device D1 is located in room V1 ) and
      ( the device D1 can measure the environment variable temperature ) and
      ( the value V1 == "r1")</pre>
<p>Expanding on and explaining why certain facts are believed to be true:</p>
<pre>the room r1 has the environment variable temperature that can be measured and that can be controlled
    because
the thermometer named t1 is located in the room r1 and can measure the environment variable temperature
    and
the radiator valve v1 is located in the room r1 and can control the environment variable temperature</pre>
<p>The fact that the devices communicate in CE means the user can passively observe the interactions. But whilst CE is human readable, it isn&#8217;t necessarily human writeable. So some of the research is also looking at how to bridge from NL to CE using a confirm interaction:</p>
<pre>NL: The thermometer in the living room has moved to the dining room
CE: the thermometer t1 is located in the room r2</pre>
<p>Whilst the current research work is focused on scenarios for civic agencies &#8211; for example managing information exchange in a policing context, I&#8217;m interested in applying this work to the IoT domain.</p>
<p>With these pieces, you can begin to see how you could have an interaction like this:</p>
<pre>
    User: I will be late home tonight.
    House: the house will have a state of occupied at 1900
    User: confirmed
    House: the room r1 has a temperature with minimum allowable value 20 after time 1900
           the roomba, vc1, has a clean cycle scheduled for time 1800
</pre>
<p>Of course this is still quite dry and formal. It would be much more human, more engaging, if the devices came with their own genuine people personality. Or at least, the appearance of one.</p>
<pre>
    User: I will be late home tonight.
    House: Sorry to hear that, shall I tell everyone to expect you back by 7?
    User: yes please    
    Thermometer: I'll make sure its warm when you get home
    Roomba: *grumble*
</pre>
<p>I always picture the Roomba as being a morose, reticent creature who really hates its own existence. We have one in the kitchen next to our lab at work, set to clean at 2am. If we leave the door to the lab open, it heads in and, without fail, maroons itself on a set of bar stools we have with a sloped base. Some might call that a fault in its programming, much like Marvin, but I like to think its just trying to find a way to end it all.</p>
<p>This is all some way from having a fully interactive chat room for your devices. But the building blocks are there and I&#8217;ll be exploring them some more.</p>
]]></content:encoded>
	<enclosure url="" length="" type="" />
		</item>
		<item>
		<title>A Conversational Internet of Things – ThingMonk talk</title>
		<link>http://eightbar.co.uk/2014/12/04/a-conversational-internet-of-things-thingmonk-talk-2/</link>
		<pubDate>Thu, 04 Dec 2014 22:00:55 +0000</pubDate>
		<dc:creator><![CDATA[Nick O'Leary]]></dc:creator>
				<category><![CDATA[Events]]></category>
		<category><![CDATA[Planet]]></category>
		<category><![CDATA[eightbar]]></category>

		<guid isPermaLink="false">http://knolleary.net/?p=1663</guid>
		<description><![CDATA[Earlier this year, Tom Coates wrote a blog post about his session at this year&#8217;s O&#8217;Reilly Foo Camp. Over tea with colleagues, we talked about some of the ideas from the post and how some of our research work might be interesting when applied to them. One thing led to another and I found myself [&#8230;] <a href="http://eightbar.co.uk/2014/12/04/a-conversational-internet-of-things-thingmonk-talk-2/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p><i>Earlier this year, Tom Coates wrote a <a href="https://medium.com/product-club/interacting-with-a-world-of-connected-objects-875b4a099099">blog post</a> about his session at this year&#8217;s O&#8217;Reilly Foo Camp. Over tea with colleagues, we talked about some of the ideas from the post and how some of our research work might be interesting when applied to them.</i></p>
<p>One thing led to another and I found myself talking about it at ThingMonk this year. What follows is a slightly expanded version of my talk.<br />
</p>
<hr />
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-0-300x168.png" alt="ciot-0" width="300" height="168" class="aligncenter size-medium wp-image-1666" style="box-shadow: 1px 1px 8px #999;" /></p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-2-300x168.png" alt="ciot-2" width="300" height="168" class="aligncenter size-medium wp-image-1667" style="box-shadow: 1px 1px 8px #999;" /></p>
<p><b>Humanising Things</b></p>
<p>We have a traditional of putting human faces on things. Whether it&#8217;s literally seeing faces on the Things in our everyday lives, such as the <a href="https://www.flickr.com/photos/dbtelford/6967361278/">drunk octopus</a> spoiling for a fight, or possibly the most <a href="https://www.flickr.com/photos/blackbeltjones/5089926442/">scary drain pipe</a> ever.</p>
<p>Equally, we have a tendency to put a human persona onto things. The advent of Twitter brought an onslaught of Things coming online. It seemingly isn&#8217;t possible for me to do a talk without at least a fleeting mention of Andy Standford-Clark&#8217;s twittering ferries; where regular updates are provided for where each ferry is.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-5-300x168.png" alt="ciot-5" width="300" height="168" class="aligncenter size-medium wp-image-1668" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>One of the earliest Things on Twitter was Tower Bridge. Tom Armitage, who was working near to the bridge at the time, wrote some code that grabbed the schedule for the bridge opening and closing times, and created the account to relay that information.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-6-300x168.png" alt="ciot-6" width="300" height="168" class="aligncenter size-medium wp-image-1669" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>One key difference between the ferries and the bridge is that the ferries are just relaying information, a timestamp and a position, whereas the bridge is speaking to us in the first-person. This small difference immediately begins to bring a more human side to the account.<br />
But ultimately, they are simple accounts that relay their state with whomever is following them.</p>
<p>This sort of thing seems to have caught on particularly with the various space agencies. We no longer appear able to send a robot to Mars, or land a probe on a comet without an accompanying twitter account bringing character to the events.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-7-300x168.png" alt="ciot-7" width="300" height="168" class="aligncenter size-medium wp-image-1683" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>There&#8217;s always a sense of excitement when these inanimate objects start to have a conversation with one another. The conversations between the philae lander and its orbiter were particularly touching as they waved goodbye to one another. Imagine, the lander, which was launched into space years before Twitter existed, chose to use its last few milliamps of power to send a final goodbye.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-8-300x168.png" alt="ciot-8" width="300" height="168" class="aligncenter size-medium wp-image-1684" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>But of course as soon as you peek behind the curtain, you see someone running Tweetdeck, logged in and typing away. I was watching the live stream as the ESA team were nervously awaiting to hear from philae. And I noticed the guy in the foreground, not focused on the instrumentation as his colleagues were, but rather concentrating on his phone. Was he the main behind the curtain, preparing Philae&#8217;s first tweet from the surface? Probably not, but for the purposes of this talk, let&#8217;s pretend he was.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-9-300x168.png" alt="ciot-9" width="300" height="168" class="aligncenter size-medium wp-image-1670" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>The idea of giving Things a human personality isn&#8217;t a new idea. There is a wealth of rigorous scientific research in this area.</p>
<p>One esteemed academic, Douglas Adams, tells us about the work done by the The Sirius Cybernetics Corporation, who invented a concept called Genuine People Personalities (&#8220;GPP&#8221;) which imbue their products with intelligence and emotion.</p>
<p>He writes:</p>
<blockquote><p>Thus not only do doors open and close, but they thank their users for using them, or sigh with the satisfaction of a job well done. Other examples of Sirius Cybernetics Corporation&#8217;s record with sentient technology include an armada of neurotic elevators, hyperactive ships&#8217; computers and perhaps most famously of all, Marvin the Paranoid Android. Marvin is a prototype for the GPP feature, and his depression and &#8220;terrible pain in all the diodes down his left side&#8221; are due to unresolved flaws in his programming.
</p></blockquote>
<p>In a related field, we have the <a href="http://reddwarf.wikia.com/wiki/Talkie_Toaster">Talkie Toaster</a> created by Crapola, Inc and seen aboard Red Dwarf. The novelty kitchen appliance was, on top of being defective, only designed to provide light conversation at breakfast time, and as such it was totally single-minded and tried to steer every conversation to the subject of toast.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-13-300x168.png" alt="ciot-13" width="300" height="168" class="aligncenter size-medium wp-image-1671" style="box-shadow: 1px 1px 8px #999;" /></p>
<p><b>Seam[less|ful]ness</b></p>
<p>In this era of the Internet of Things, we talk about a future where our homes and workplaces are full of connected devices, sharing their data, making decisions, collaborating to make our lives &#8216;better&#8217;.</p>
<p>Whilst there are people who celebrate this invisible ubiquity and utility of computing, the reality is going to much more messy.</p>
<p><a href="http://en.wikipedia.org/wiki/Mark_Weiser">Mark Weiser</a>, Chief Scientist at Xerox PARC, coined the term &#8220;ubiquitous computing&#8221; in 1988.</p>
<blockquote><p>Ubiquitous computing names the third wave in computing, just now beginning. First were mainframes, each shared by lots of people. Now we are in the personal computing era, person and machine staring uneasily at each other across the desktop. Next comes ubiquitous computing, or the age of calm technology, when technology recedes into the background of our lives.</p></blockquote>
<p>Discussion of Ubiquitous Computing often celebrated the idea of seamless experiences between the various devices occupying our lives. But in reality, Mark Weiser advocated for the opposite; that seamlessness was undesirable and self-defeating attribute of such a system.</p>
<p>He preferred a vision of &#8220;Seamfulness, with beautiful seams&#8221;</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-15-300x168.png" alt="ciot-15" width="300" height="168" class="aligncenter size-medium wp-image-1673" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>The desire to present a single view of the system, with no joins, is an unrealistic aspiration in the face of the cold realities of wifi connectivity, battery life, system reliability and whether the Cloud is currently turned on.</p>
<p>Presenting a user with a completely monolithic system gives them no opportunity to connect with and begin to understand the constituent parts. That is not it say this information is needed to all users all of the time. But there is clearly utility to some users some of the time.</p>
<p>When you come home from work and the house is cold, what went wrong? Did the thermostat in the living room break and decide it was the right temperature already? Did the message from the working thermostat fail to get to the boiler? Is the boiler broken? Did you forgot to cancel the entry in your calendar saying you&#8217;d be late home that day?</p>
<p>Without some appreciation of the moving parts in a system, how can a user feel any ownership or empowerment when something goes wrong with it. Or worse yet, how can they avoid feeling anything other than intimidated by this monolithic system that simply says &#8220;I&#8217;m Sorry Dave, I&#8217;m afraid I can&#8217;t do that&#8221;.</p>
<p>Tom Armitage <a href="http://tomarmitage.com/2014/12/02/some-of-these-things-are-not-like-the-others/">wrote up his</a> talk from Web Directions South and published it earlier this week, just as I was writing this talk. He covers a lot of what I&#8217;m talking about here so much more eloquently than I am &#8211; go read it. One piece his post pointed me at that I hadn&#8217;t seen was <a href="http://techcrunch.com/2014/10/14/august-smart-lock-on-sale/">Techcrunch&#8217;s recent review of August&#8217;s Smart Lock</a>.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-16-300x168.png" alt="ciot-16" width="300" height="168" class="aligncenter size-medium wp-image-1674" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>Tom picked out some choice quotes from the review which I&#8217;ll share here:</p>
<blockquote><p>“…much of the utility of the lock was negated by the fact that I have roommates and not all of them were willing or able to download the app to test it out with me […] My dream of using Auto-Unlock was stymied basically because my roommates are luddites.”
</p></blockquote>
<blockquote><p>“Every now and then it didn’t recognize my phone as I approached the door.”</p></blockquote>
<blockquote><p>“There was also one late night when a stranger opened the door and walked into the house when August should have auto-locked the door.”</p></blockquote>
<p>This is the reason for having beautiful seams; seams help you understand the edges of a devices sphere of interaction, but should not be so big to trip you up. Many similar issues exists with IP connected light bulbs. When I need to remember which app to launch on my phone depending on which room I&#8217;m walking into, and which bulbs happen to be in there, the seams have gotten too big.</p>
<p>In a recent <a href="https://medium.com/product-club/interacting-with-a-world-of-connected-objects-875b4a099099">blog post</a>, Tom Coates wrote about the idea of a chatroom for the house &#8211; go read it.</p>
<blockquote><p>Much like a conference might have a chatroom, so might a home. And it might be a space that you could duck into as you pleased to see what was going on. By turning the responses into human language you could make the actions of the objects less inscrutable and difficult to understand.</p></blockquote>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-17-300x168.png" alt="ciot-17" width="300" height="168" class="aligncenter size-medium wp-image-1675" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>This echoes back to the world of Twitter accounts for Things. But rather than them being one-sided conversations presenting raw data in a more consumable form, or Wizard-of-Oz style man-behind-the-curtain accounts, a chatroom is a space where the conversation can flow both ways; both between the owner and their devices, but also between the devices themselves.</p>
<p>What might it take to turn such a chatroom into a reality?</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-18-300x168.png" alt="ciot-18" width="300" height="168" class="aligncenter size-medium wp-image-1676" style="box-shadow: 1px 1px 8px #999;" /></p>
<p><b>Getting Things Talking</b></p>
<p>Getting Things connected is no easy task.</p>
<p>We&#8217;re still in the early days of the protocol wars.</p>
<p>Whilst I have to declare allegiance to the now international OASIS standard MQTT, I&#8217;m certainly not someone who thinks one protocol will rule them all. It pains me whenever I see people make those sorts of claims. But that&#8217;s a talk for a different day.</p>
<p>Whatever your protocol of choice, there are an emerging core set that seem to be the more commonly talked about. Each with its strengths and weaknesses. Each with its backers and detractors.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-19-300x168.png" alt="ciot-19" width="300" height="168" class="aligncenter size-medium wp-image-1677" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>What (mostly) everyone agrees on is the need for more than just efficient protocols for the Things to communicate by. A protocol is like a telephone line. It&#8217;s great that you and I have agreed on the same standards so when I dial this number, you answer. But what do we say to each other once we&#8217;re connected? A common protocol does not mean I understand what you&#8217;re trying to say to me.</p>
<p>And thus began the IoT meta-model war.</p>
<p>There certainly a lot of interesting work being done in this area.</p>
<p>For example, HyperCat, a consortium of companies coming out of a Technology Strategy Board funded Demonstrator project in the last year or so.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-21-300x168.png" alt="ciot-21" width="300" height="168" class="aligncenter size-medium wp-image-1678" style="box-shadow: 1px 1px 8px #999;" /></p>
<blockquote><p>HyperCat is an open, lightweight JSON-based hypermedia catalogue format for exposing collections of URIs. Each HyperCat catalogue may expose any number of URIs, each with any number of RDF-like triple statements about it. HyperCat is simple to work with and allows developers to publish linked-data descriptions of resources.
</p></blockquote>
<p>URIs are great. The web is made of them and they are well understood. At least, they are well understood by machines. What we&#8217;re lacking is the human view of this world. How can this well-formed, neatly indented JSON be meaningful or helpful to the user who is trying to understand what is happening.</p>
<p>This is by no means a criticism of HyperCat, or any of the other efforts to create models of the IoT. They are simply trying to solve a different set of problems to the ones I&#8217;m talking about today.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-23-300x168.png" alt="ciot-23" width="300" height="168" class="aligncenter size-medium wp-image-1679" style="box-shadow: 1px 1px 8px #999;" /></p>
<p><b>Talking to Computers</b></p>
<p>We live in an age where the talking to computers is becoming less the reserve of science fiction.</p>
<p>Siri, OK Google, Cortana all exist as ways to interact with the devices in your pocket. My four year old son walks up to me when I have my phone out and says: &#8220;OK Google, show me a picture of the Octonauts&#8221; and takes over my phone without even having to touch it. To him, as to me, voice control is still a novelty. But I wonder what his 6 month old sister will find to be the intuitive way of interacting with devices in a few years time.</p>
<p>The challenge of Natural Language Parsing, NLP, is one of the big challenges in Computer Science. Correctly identifying the words being spoken is relatively well solved. But understanding what those words mean, what intent they try to convey, is still a hard thing to do.</p>
<p>To answer the question &#8220;Which bat is your favourite?&#8221; without any context is hard to do. Are we talking to a sportsman with their proud collection of cricket bats? Is it the zoo keeper with their colony of winged animals. Or perhaps a comic book fan being asked to chose between George Clooney and Val Kilmer.</p>
<p>Context is also key when you want to hold a conversation. The English language is riddled with ambiguity. Our brains are constantly filling in gaps, making theories and assertions over what the other person is saying. The spoken word also presents its own challenges over the written word.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-28-300x168.png" alt="ciot-28" width="300" height="168" class="aligncenter size-medium wp-image-1680" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>&#8220;Hu was the premiere of China until 2012&#8243;</p>
<p>When said aloud, you don&#8217;t know if I&#8217;ve asked you a question or stated a fact. When written down, it is much clearer.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-29-300x168.png" alt="ciot-29" width="300" height="168" class="aligncenter size-medium wp-image-1681" style="box-shadow: 1px 1px 8px #999;" /></p>
<p>In their emerging technology report for 2014, Gartner put the Internet of Things at the peak of inflated expectation. But if you look closely at the curve, up at the peak, right next to IoT, is NLP Question Answering. If this was a different talk, I&#8217;d tell you all about how IBM Watson is solving those challenges. But this isn&#8217;t that talk.</p>
<p><img src="http://knolleary.net/blog/wp-content/uploads/2014/12/ciot-30-300x168.png" alt="ciot-30" width="300" height="168" class="aligncenter size-medium wp-image-1682" style="box-shadow: 1px 1px 8px #999;" /></p>
<p><b>A Conversational Internet of Things</b></p>
<p>To side step a lot of the challenges of NLP, one area of research we&#8217;re involved with is that of Controlled Natural Language and in particular, Controlled English.</p>
<p>CE is designed to be readable by a native English speaker whilst representing information in a structured and unambiguous form. It is structured by following a simple but fully defined syntax, which may be parsed by a computer system.</p>
<p>It is unambiguous by using only words that are defined as part of a conceptual model.</p>
<p>CE serves as a language that is both understandable by human and computer system &#8211; which allows them to communicate.</p>
<p>For example,</p>
<pre>there is a thermometer named t1 that is located in the room r1</pre>
<p>A simple sentence that establishes the fact that a thermometer exists in a given room.</p>
<pre>the thermometer t1 can measure the environment variable temperature</pre>
<p>Each agent in the system builds its own model of the world that can be used to define concepts such thermometer, temperature, room and so on. As the model is itself defined in CE, the agents build their models through conversing in CE.</p>
<pre>there is a radiator valve v1 that is located in the room r1
the radiator valve v1 can control the environment variable temperature</pre>
<p>It is also able to using reasoning to determine new facts. </p>
<pre>the room r1 has the environment variable temperature that can be measured and that can be controlled</pre>
<p>As part of some research work with Cardiff University, we&#8217;ve been looking at how CE can be extended to a conversational style of interaction.</p>
<p>These range from exchanging facts between devices &#8211; the tell</p>
<pre>the environment variable temperature in room r1 has value "21"</pre>
<p>Being able to ask question &#8211; ask-tell</p>
<pre>for which D1 is it true that
      ( the device D1 is located in room V1 ) and
      ( the device D1 can measure the environment variable temperature ) and
      ( the value V1 == "r1")</pre>
<p>Expanding on and explaining why certain facts are believed to be true:</p>
<pre>the room r1 has the environment variable temperature that can be measured and that can be controlled
    because
the thermometer named t1 is located in the room r1 and can measure the environment variable temperature
    and
the radiator valve v1 is located in the room r1 and can control the environment variable temperature</pre>
<p>The fact that the devices communicate in CE means the user can passively observe the interactions. But whilst CE is human readable, it isn&#8217;t necessarily human writeable. So some of the research is also looking at how to bridge from NL to CE using a confirm interaction:</p>
<pre>NL: The thermometer in the living room has moved to the dining room
CE: the thermometer t1 is located in the room r2</pre>
<p>Whilst the current research work is focused on scenarios for civic agencies &#8211; for example managing information exchange in a policing context, I&#8217;m interested in applying this work to the IoT domain.</p>
<p>With these pieces, you can begin to see how you could have an interaction like this:</p>
<pre>
    User: I will be late home tonight.
    House: the house will have a state of occupied at 1900
    User: confirmed
    House: the room r1 has a temperature with minimum allowable value 20 after time 1900
           the roomba, vc1, has a clean cycle scheduled for time 1800
</pre>
<p>Of course this is still quite dry and formal. It would be much more human, more engaging, if the devices came with their own genuine people personality. Or at least, the appearance of one.</p>
<pre>
    User: I will be late home tonight.
    House: Sorry to hear that, shall I tell everyone to expect you back by 7?
    User: yes please    
    Thermometer: I'll make sure its warm when you get home
    Roomba: *grumble*
</pre>
<p>I always picture the Roomba as being a morose, reticent creature who really hates its own existence. We have one in the kitchen next to our lab at work, set to clean at 2am. If we leave the door to the lab open, it heads in and, without fail, maroons itself on a set of bar stools we have with a sloped base. Some might call that a fault in its programming, much like Marvin, but I like to think its just trying to find a way to end it all.</p>
<p>This is all some way from having a fully interactive chat room for your devices. But the building blocks are there and I&#8217;ll be exploring them some more.</p>
]]></content:encoded>
	<enclosure url="" length="" type="" />
		</item>
		<item>
		<title>Went to Designcamp, got the T-Shirt</title>
		<link>http://eightbar.co.uk/2014/11/12/went-to-designcamp-got-the-t-shirt/</link>
		<pubDate>Wed, 12 Nov 2014 16:12:03 +0000</pubDate>
		<dc:creator><![CDATA[Nick O'Leary]]></dc:creator>
				<category><![CDATA[Life]]></category>
		<category><![CDATA[Planet]]></category>
		<category><![CDATA[eightbar]]></category>

		<guid isPermaLink="false">http://knolleary.net/?p=1658</guid>
		<description><![CDATA[Last month, I was fortunate enough to fly off to Austin with a group of colleagues for a week long IBM Design Thinking camp. It was an opportunity to get away from the day job, with laptops all-but banned, and have a deep-dive into what IBM Design is about and how it can be applied. [&#8230;] <a href="http://eightbar.co.uk/2014/11/12/went-to-designcamp-got-the-t-shirt/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Last month, I was fortunate enough to fly off to Austin with a group of colleagues for a week long IBM Design Thinking camp. It was an opportunity to get away from the day job, with laptops all-but banned, and have a deep-dive into what IBM Design is about and how it can be applied.</p>
<p>As a relatively new effort within the company, IBM Design sets out to bring a focus back to where it should be; the human-experience of our products and services. This isn&#8217;t just about making pretty user interfaces; it is the entire experience of our products.</p>
<p>As an engineer, the temptation is always there to create shiny new features. But no matter how shiny it is, if it isn&#8217;t what a user needs, then it&#8217;s a waste of effort. The focus has to be on what the user wants to be able to do. This is something I&#8217;ve always tried to do with Node-RED; we often get suggestions for features that, once you start picking at them, are really solutions looking for a problem. Once you work back and identify the problem, we&#8217;re often able to identify alternative solutions that are even better.</p>
<p><a href="https://www.flickr.com/photos/knolleary/15569114551" title="P1070048 by Nick O&#x27;Leary, on Flickr"><img src="https://farm4.staticflickr.com/3945/15569114551_a13cf196ce.jpg" width="500" height="375" alt="P1070048"/></a></p>
<p>It&#8217;s often just a matter of asking the right question; At Designcamp, the very first exercise we were asked to do was to draw a new type of vase. Everyone drew something that looked vaguely vase-like. Then (spoilers&#8230;) we were asked to draw a better way to display flowers. At this point we got lots of decidedly un-vase-like ideas that were much more imaginative. It&#8217;s the difference between asking for a feature and asking for an idea. The former presupposes a lot about the nature of the answer, the latter is focused on not just the <b>what</b>, but also the <b>why</b>.</p>
<p>This relentless focus on the user isn&#8217;t a new idea. GDS, who are doing incredible things with government services, have it as their very first <a href="https://www.gov.uk/design-principles">Design Principle</a>. But it is refreshing to see this focus being brought to bear within a transformation of how the entire company operates.</p>
<p>Oh, and of course being in Austin, we got to screen print our own IBM Designcamp T-Shirts to commemorate the visit.</p>
<p><a href="https://www.flickr.com/photos/knolleary/15369908897" title="Go to Designcamp, screen print your own t-shirt. Obvs. by Nick O&#x27;Leary, on Flickr"><img src="https://farm4.staticflickr.com/3947/15369908897_5ccc35555c.jpg" width="500" height="500" alt="Go to Designcamp, screen print your own t-shirt. Obvs."/></a></p>
<p>Lots more photos from the week over on <a href="https://www.flickr.com/photos/knolleary/sets/72157648445616348/">flickr</a>.</p>
]]></content:encoded>
	<enclosure url="" length="" type="" />
		</item>
		<item>
		<title>Come On Tim!</title>
		<link>http://eightbar.co.uk/2007/06/28/come-on-tim/</link>
		<comments>http://eightbar.co.uk/2007/06/28/come-on-tim/#comments</comments>
		<pubDate>Thu, 28 Jun 2007 14:30:29 +0000</pubDate>
		<dc:creator><![CDATA[Nick O'Leary]]></dc:creator>
				<category><![CDATA[Hursley]]></category>
		<category><![CDATA[Second Life]]></category>
		<category><![CDATA[Virtual worlds]]></category>

		<guid isPermaLink="false">http://eightbar.co.uk/?p=354</guid>
		<description><![CDATA[Whilst Ian and Roo are busy on site, keeping the virtual Wimbledon wheels turning and evangelising as they do best, I&#8217;ve found myself spending more and more time hanging around the build on &#8220;IBM 7&#8221;. So much so, I felt &#8230; <a href="http://eightbar.co.uk/2007/06/28/come-on-tim/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Whilst Ian and Roo are busy on site, keeping the virtual Wimbledon wheels turning and evangelising as they do best, I&#8217;ve found myself spending more and more time hanging around the build on &#8220;IBM 7&#8221;. </p>
<p>So much so, I felt I needed to show some good old-fashioned biased support for the Brits. My suggestion of making the virtual Henman twice the size of the other players didn&#8217;t get very far. These views are my own and not necessarily those of IBM. <img src="https://s.w.org/images/core/emoji/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<div style="text-align:center;"><a href="http://www.flickr.com/photos/knolleary/648826849/" title="Photo Sharing"><img src="http://farm2.static.flickr.com/1424/648826849_62b07dbe7a.jpg" width="500" height="334" alt="Come on Tim" /></a></div>
<p><i>Update</i>: <a href="http://news.bbc.co.uk/sport1/hi/tennis/6244822.stm">seems</a> my support wasn&#8217;t quite enough.</p>
]]></content:encoded>
			<wfw:commentRss>http://eightbar.co.uk/2007/06/28/come-on-tim/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
		</item>
		<item>
		<title>Spitfire Flypast of Hursley House</title>
		<link>http://eightbar.co.uk/2006/12/08/spitfire-flypast-of-hursley-house/</link>
		<comments>http://eightbar.co.uk/2006/12/08/spitfire-flypast-of-hursley-house/#comments</comments>
		<pubDate>Fri, 08 Dec 2006 15:35:25 +0000</pubDate>
		<dc:creator><![CDATA[Nick O'Leary]]></dc:creator>
				<category><![CDATA[Hursley]]></category>

		<guid isPermaLink="false">http://eightbar.co.uk/?p=241</guid>
		<description><![CDATA[As a mark of respect for a member of the original Spitfire design team who passed away recently, the Spitfire Society arranged a flypast of Hursley House on Friday 8th December. Spitfire Flypast at Hursley, UK &#8211; Google Video I &#8230; <a href="http://eightbar.co.uk/2006/12/08/spitfire-flypast-of-hursley-house/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>As a mark of respect for a member of the original Spitfire design team who passed away recently, the Spitfire Society arranged a flypast of Hursley House on Friday 8th December.</p>
<p><embed style="width:400px; height:326px;" id="VideoPlayback" type="application/x-shockwave-flash" src="http://video.google.com/googleplayer.swf?docId=7988937978666904593&#038;hl=en-GB" flashvars=""> </embed></p>
<p><a href="http://video.google.co.uk/videoplay?docid=7988937978666904593&#038;hl=en-GB">Spitfire Flypast at Hursley, UK &#8211; Google Video</a></p>
<p>I forgot my camera, so my phone stood in. The video quality isn&#8217;t great, but it does give some sense of the event. There were plenty of photographers out on the lawn, so I&#8217;m sure <a href="http://flickr.com">Flickr</a> will soon be flooded with photos from the event.</p>
<p>Hursley was where the Spitfire engines were developed &#8211; long before IBM got there.</p>
]]></content:encoded>
			<wfw:commentRss>http://eightbar.co.uk/2006/12/08/spitfire-flypast-of-hursley-house/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
		<item>
		<title>IBM &#038; Dojo</title>
		<link>http://eightbar.co.uk/2006/06/06/ibm-dojo/</link>
		<pubDate>Tue, 06 Jun 2006 14:56:27 +0000</pubDate>
		<dc:creator><![CDATA[Nick O'Leary]]></dc:creator>
				<category><![CDATA[News]]></category>
		<category><![CDATA[Technology]]></category>

		<guid isPermaLink="false">http://eightbar.co.uk/?p=91</guid>
		<description><![CDATA[Given the buzz of Web2.0, its not surprising to see lots of ajax-based toolkits emerge from lots of different sources, Yahoo! and Google included. I am glad to see that IBM are getting involved by contributing to an open source &#8230; <a href="http://eightbar.co.uk/2006/06/06/ibm-dojo/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Given the buzz of Web2.0, its not surprising to see lots of ajax-based toolkits emerge from lots of different sources, Yahoo! and Google included.</p>
<p>I am glad to see that <a href="http://www.marketwire.com/mw/release_html_b1?release_id=133309">IBM</a> are getting involved by contributing to an open source project.</p>
<p><a href="http://dojotoolkit.org/">Dojo</a> has been on my list of things to learn about for a while now.  As a starting point, I can recommend <a href="http://alex.dojotoolkit.org/06/XTech/talk.txt">this</a> talk by Alex Russell of the Dojo Foundation that was given at the XTech 2006 conference.</p>
]]></content:encoded>
			</item>
		<item>
		<title>Second Life Ecosystem</title>
		<link>http://eightbar.co.uk/2006/05/31/second-life-ecosystem/</link>
		<comments>http://eightbar.co.uk/2006/05/31/second-life-ecosystem/#comments</comments>
		<pubDate>Wed, 31 May 2006 18:09:17 +0000</pubDate>
		<dc:creator><![CDATA[Nick O'Leary]]></dc:creator>
				<category><![CDATA[Second Life]]></category>

		<guid isPermaLink="false">http://eightbar.co.uk/?p=87</guid>
		<description><![CDATA[Here is fascinating example of what is possible within Second Life. Laukosargas Svarog is a veteran of the UK games industry including some time spent on Lionhead Studios&#8217; Black &#038; White. Having taken some time of to raise a child &#8230; <a href="http://eightbar.co.uk/2006/05/31/second-life-ecosystem/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p><a href="http://nwn.blogs.com/nwn/2006/05/god_game.html">Here</a> is fascinating example of what is possible within Second Life.</p>
<p>Laukosargas Svarog is a veteran of the UK games industry including some time spent on Lionhead Studios&#8217; Black &#038; White. Having taken some time of to raise a child at home, she has been putting her creative juices into the world of SL.</p>
<p>In just one year, her island of Svarga has been developed into a &#8216;fully-functioning ecosystem&#8217; with early evidence of emergent behaviour in the plant-life she has created.</p>
<p>Just one of the many directions the blank canvas that is SL can be taken.</p>
]]></content:encoded>
			<wfw:commentRss>http://eightbar.co.uk/2006/05/31/second-life-ecosystem/feed/</wfw:commentRss>
		<slash:comments>3</slash:comments>
		</item>
		<item>
		<title>HTX Event: Techconnect</title>
		<link>http://eightbar.co.uk/2006/05/24/htx-event-techconnect/</link>
		<comments>http://eightbar.co.uk/2006/05/24/htx-event-techconnect/#comments</comments>
		<pubDate>Wed, 24 May 2006 13:53:06 +0000</pubDate>
		<dc:creator><![CDATA[Nick O'Leary]]></dc:creator>
				<category><![CDATA[Events]]></category>
		<category><![CDATA[Hursley]]></category>

		<guid isPermaLink="false">http://eightbar.co.uk/?p=79</guid>
		<description><![CDATA[As a part of the week-long Hursley Technical Exchange, today saw the Techconnect event take place. This is an opportunity for people from across the whole lab to produce and present a set of posters on a particular piece of &#8230; <a href="http://eightbar.co.uk/2006/05/24/htx-event-techconnect/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>As a part of the week-long <a href="http://eightbar.co.uk/2006/05/22/h-t-the-x/">Hursley Technical Exchange</a>, today saw the Techconnect event take place. This is an opportunity for people from across the whole lab to produce and present a set of posters on a particular piece of innovation they have been involved with.</p>
<p>I spent a couple of hours this lunchtime stood in the main hall of <a href="http://www.flickr.com/photos/smartypants/100215350/in/set-72057594065220879/">Hursley House</a> presenting my poster on the &#8220;<a href="http://alphaworks.ibm.com/tech/svctools">Scripting Tools for SAN Volume Controller</a>&#8221; (<em>gratuitous plug</em>).</p>
<p>It was great to be able to talk to people from many areas of the lab that I wouldn&#8217;t have normal reason to speak with. It was also very interesting to see what else is going on within the lab at a very low level.</p>
<p>This type of internal promotion of innovation and idea sharing is a great example of how IBM engenders a culture of innovation and thought-leading with our customers &#8211; we have to be innovative inside, to be innovative outside.</p>
]]></content:encoded>
			<wfw:commentRss>http://eightbar.co.uk/2006/05/24/htx-event-techconnect/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
	</channel>
</rss>
